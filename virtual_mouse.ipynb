{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Getting Prerequisites**\n",
    "Before starting to work on Object Detection module, following components need to be installed :\n",
    "> -  Python\n",
    "\n",
    "# **Setting Up The Environment**\n",
    "For all the other libraries we can use pip or conda to install them. The code is provided below:<br>\n",
    "> -  pip install OpenCV\n",
    "> -  pip install wxPython\n",
    "> -  pip install pynput"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Required Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - OpenCV is used to handle image and video operations\n",
    "> - NumPy handles mathematical operations\n",
    "> - wxPython is a cross platform toolkit for creating desktop GUI applications\n",
    "> - pynput contains classes for controlling and monitoring the mouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import wx\n",
    "from pynput.mouse import Button, Controller"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create object to handle the mouse and also capture display size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mouse = Controller()\n",
    "app = wx.App(False)\n",
    "sx, sy = wx.GetDisplaySize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, find out the range of HSV values for particular color which we want to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowerBound = np.array([170, 80, 110])\n",
    "upperBound = np.array([179, 255, 255])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below code is used to open built-in webcam in particular display ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "capx, capy = 320, 240\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3, capx)\n",
    "cap.set(4, capy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Morphological transformations are some simple operations based on the image shape. It is normally performed on binary images. It needs two inputs, one is our original image, second one is called structuring element or kernel which decides the nature of operation. Two basic morphological operators are Erosion and Dilation. Then its variant forms like Opening, Closing, Gradient etc also comes into play.\n",
    "\n",
    "Opening is just another name of erosion followed by dilation. It is useful in removing noise.\n",
    "> <img src=\"images/opening.png\" alt=\"Alt text that describes the graphic\" title=\"Title text\" />\n",
    "\n",
    "Closing is reverse of Opening, Dilation followed by Erosion. It is useful in closing small holes inside the foreground objects, or small black points on the object.\n",
    "> <img src=\"images/closing.png\" alt=\"Alt text that describes the graphic\" title=\"Title text\" />\n",
    "\n",
    "Above operations will be used later in the module. But to use them we need to define variables which contains binary data to handle those operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernelOpen = np.ones((5, 5))\n",
    "kernelClose = np.ones((20, 20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to use damping factor. Which will manage our frequency of the shaking hand and will lower the amount for enhancement. So define few variables to use them in damping factor formula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mLocOld = np.array([0, 0])\n",
    "mouseLoc = np.array([0, 0])\n",
    "DampingFactor = 3\n",
    "\n",
    "pinchFlag = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "openx, openy, openw, openh = 0, 0, 0, 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, first start capturing each frame and convert it from BGR to HSV color. Use morphological operation OPEN and CLOSE on it.\n",
    "\n",
    "We will use contours in our module. Contours can be explained simply as a curve joining all the continuous points (along the boundary), having same color or intensity. The contours are a useful tool for shape analysis and object detection and recognition.\n",
    "\n",
    "### Contours == 1:\n",
    "If there is only contour detected, then we will use mouse press operation. We will use only mouse press which is holding the left mouse click.\n",
    "\n",
    "### Contours == 2:\n",
    "If there are 2 contours detected, then we will use mouse position operation which simply means moving the mouse around on the screen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    ret, img = cap.read()\n",
    "    # img = cv2.resize(img, (340, 220))\n",
    "\n",
    "    imgHSV = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    mask = cv2.inRange(imgHSV, lowerBound, upperBound)\n",
    "    maskOpen = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernelOpen)\n",
    "    maskClose = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernelClose)\n",
    "\n",
    "    maskFinal = maskClose\n",
    "\n",
    "    conts, h = cv2.findContours(maskFinal.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "    if len(conts) == 2:\n",
    "\n",
    "        if pinchFlag == 1:\n",
    "            pinchFlag = 0\n",
    "            mouse.release(Button.left)\n",
    "\n",
    "        x1, y1, w1, h1 = cv2.boundingRect(conts[0])\n",
    "        x2, y2, w2, h2 = cv2.boundingRect(conts[1])\n",
    "        cv2.rectangle(img, (x1, y1), (x1 + w1, y1 + h1), (255, 0, 0), 2)\n",
    "        cv2.rectangle(img, (x2, y2), (x2 + w2, y2 + h2), (255, 0, 0), 2)\n",
    "        cx1 = x1 + int(w1 / 2)\n",
    "        cy1 = y1 + int(h1 / 2)\n",
    "        cx2 = x2 + int(w2 / 2)\n",
    "        cy2 = y2 + int(h2 / 2)\n",
    "        cx = int((cx1 + cx2) / 2)\n",
    "        cy = int((cy1 + cy2) / 2)\n",
    "        cv2.line(img, (cx1, cy1), (cx2, cy2), (255, 0, 0), 2)\n",
    "        cv2.circle(img, (cx, cy), 2, (0, 0, 255), 2)\n",
    "\n",
    "        mouseLoc = mLocOld + ((cx, cy) - mLocOld) / DampingFactor\n",
    "        mouse.position = (sx - int(mouseLoc[0] * sx / capx), int(mouseLoc[1] * sy / capy))\n",
    "        while mouse.position != (sx - int(mouseLoc[0] * sx / capx), int(mouseLoc[1] * sy / capy)):\n",
    "            pass\n",
    "        mLocOld = mouseLoc\n",
    "        openx, openy, openw, openh = cv2.boundingRect(np.array([[x1, y1], [x1 + w1, y1 + h1], [x2, y2],\n",
    "                                                                [x2 + w2, y2 + h2]]))\n",
    "\n",
    "    elif len(conts) == 1:\n",
    "\n",
    "        x, y, w, h = cv2.boundingRect(conts[0])\n",
    "\n",
    "        if pinchFlag == 0:\n",
    "            if abs((w * h - openw * openh) * 100 / (w * h)) < 30:\n",
    "                pinchFlag = 1\n",
    "                mouse.press(Button.left)\n",
    "                openx, openy, openw, openh = 0, 0, 0, 0\n",
    "\n",
    "        else:\n",
    "            cv2.rectangle(img, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "            cx = int(x + w / 2)\n",
    "            cy = int(y + h / 2)\n",
    "            cv2.circle(img, (cx, cy), int((w + h) / 4), (0, 0, 255), 2)\n",
    "\n",
    "            mouseLoc = mLocOld + ((cx, cy) - mLocOld) / DampingFactor\n",
    "            mouse.position = (sx - int(mouseLoc[0] * sx / capx), int(mouseLoc[1] * sy / capy))\n",
    "            while mouse.position != (sx - int(mouseLoc[0] * sx / capx), int(mouseLoc[1] * sy / capy)):\n",
    "                pass\n",
    "            mLocOld = mouseLoc\n",
    "\n",
    "    cv2.imshow(\"cap\", img)\n",
    "\n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k == 27:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to close the display window we use following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
